project: NeuralHamilton_v1.19_DeepONet
device: cuda:0
net: model.DeepONet
#optimizer: torch.optim.adamw.AdamW
optimizer: soap.SOAP
scheduler: hyperbolic_lr.ExpHyperbolicLR
epochs: 250
batch_size: 100
seeds: [89]
net_config:
  nodes: 512
  layers: 6
  branches: 64
optimizer_config:
  lr: 0.0031590157253615814
scheduler_config:
  upper_bound: 300
  max_iter: 250
  infimum_lr: 1.e-5
